'use client';

import { FigureCard, StatCard, ResultsChart } from '@/components';

export default function Poster() {
  return (
    <div className="min-h-screen py-8 px-4">
      {/* Poster Container */}
      <div className="poster-container max-w-7xl mx-auto rounded-3xl overflow-hidden">

        {/* Header */}
        <header className="bg-gradient-to-r from-blue-600 via-purple-600 to-indigo-700 text-white p-8">
          <div className="max-w-6xl mx-auto">
            <div className="flex items-start justify-between gap-6">
              <div className="flex-1">
                <p className="text-blue-200 font-medium mb-2">EACL 2025</p>
                <h1 className="text-4xl md:text-5xl font-bold leading-tight mb-4">
                  LitBench: A Benchmark and Dataset for Reliable Evaluation of Creative Writing
                </h1>
                <p className="text-xl text-blue-100 max-w-3xl">
                  The first standardized benchmark for creative writing verification with debiased human labels
                </p>
              </div>
              <div className="hidden lg:block">
                <div className="bg-white/10 backdrop-blur rounded-2xl p-4">
                  <div className="text-6xl text-center mb-2">üìö</div>
                  <p className="text-sm text-center text-blue-200">arXiv:2507.00769</p>
                </div>
              </div>
            </div>

            {/* Authors */}
            <div className="mt-6 pt-6 border-t border-white/20">
              <div className="flex flex-wrap gap-x-6 gap-y-2 text-sm">
                <span className="font-semibold">Daniel Fein</span>
                <span className="font-semibold">Sebastian Russo</span>
                <span className="font-semibold">Violet Xiang</span>
                <span className="font-semibold">Kabir Jolly</span>
                <span className="font-semibold">Rafael Rafailov</span>
                <span className="font-semibold">Nick Haber</span>
              </div>
              <p className="text-blue-200 text-sm mt-2">Stanford University</p>
            </div>
          </div>
        </header>

        {/* Main Content Grid */}
        <main className="p-6 md:p-8">
          <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">

            {/* Left Column */}
            <div className="space-y-6">

              {/* Motivation */}
              <section className="poster-section p-6">
                <h2 className="text-2xl font-bold text-gray-800 mb-4 flex items-center gap-2">
                  <span className="text-3xl">üéØ</span> Motivation
                </h2>
                <div className="space-y-3 text-gray-700">
                  <p>
                    Evaluating creative writing generated by LLMs remains challenging because
                    <strong className="text-blue-600"> open-ended narratives lack ground truths</strong>.
                  </p>
                  <p>
                    Without performant automated evaluation methods, off-the-shelf language models
                    are employed as zero-shot judges, yet <strong className="text-purple-600">their reliability
                    is unclear</strong> in this context.
                  </p>
                  <div className="bg-amber-50 border-l-4 border-amber-500 p-4 rounded-r-lg mt-4">
                    <p className="text-amber-800 font-medium">
                      How can we reliably evaluate creative writing at scale?
                    </p>
                  </div>
                </div>
              </section>

              {/* Dataset */}
              <section className="poster-section p-6">
                <h2 className="text-2xl font-bold text-gray-800 mb-4 flex items-center gap-2">
                  <span className="text-3xl">üìä</span> Dataset
                </h2>
                <div className="space-y-4">
                  <div className="bg-gradient-to-r from-blue-50 to-purple-50 rounded-xl p-4">
                    <h3 className="font-semibold text-gray-800 mb-2">Source: Reddit r/WritingPrompts</h3>
                    <ul className="text-sm text-gray-600 space-y-1">
                      <li>‚Ä¢ Post-2023 stories (no LLM pretraining overlap)</li>
                      <li>‚Ä¢ Average story length: 550 words</li>
                      <li>‚Ä¢ 3,543 unique stories in test set</li>
                    </ul>
                  </div>

                  <div className="space-y-3">
                    <h3 className="font-semibold text-gray-800">Debiasing Strategies:</h3>
                    <div className="grid grid-cols-1 gap-2">
                      <div className="flex items-center gap-2 text-sm">
                        <span className="w-8 h-8 rounded-full bg-green-100 flex items-center justify-center text-green-600">‚úì</span>
                        <span><strong>25%+ upvote margin</strong> for preference signal</span>
                      </div>
                      <div className="flex items-center gap-2 text-sm">
                        <span className="w-8 h-8 rounded-full bg-green-100 flex items-center justify-center text-green-600">‚úì</span>
                        <span><strong>Temporal filtering</strong> to remove timing bias</span>
                      </div>
                      <div className="flex items-center gap-2 text-sm">
                        <span className="w-8 h-8 rounded-full bg-green-100 flex items-center justify-center text-green-600">‚úì</span>
                        <span><strong>Length pruning</strong> to mitigate length bias</span>
                      </div>
                    </div>
                  </div>
                </div>
              </section>

              {/* Contributions */}
              <section className="poster-section p-6">
                <h2 className="text-2xl font-bold text-gray-800 mb-4 flex items-center gap-2">
                  <span className="text-3xl">‚≠ê</span> Contributions
                </h2>
                <div className="space-y-3">
                  {[
                    'First standardized benchmark for creative writing verification',
                    'Benchmark evaluation of off-the-shelf LLM judges',
                    'Trained reward models using Bradley-Terry & generative approaches',
                    'Human validation study confirming model alignment',
                    'Public release of dataset and reward models on HuggingFace',
                  ].map((contribution, i) => (
                    <div key={i} className="flex items-start gap-3">
                      <span className="contribution-badge text-white text-xs font-bold px-2 py-1 rounded-full">
                        {i + 1}
                      </span>
                      <p className="text-sm text-gray-700">{contribution}</p>
                    </div>
                  ))}
                </div>
              </section>
            </div>

            {/* Middle Column */}
            <div className="space-y-6">

              {/* Key Stats */}
              <div className="grid grid-cols-2 gap-4">
                <StatCard value="2,480" label="Test Comparisons" sublabel="Debiased pairs" />
                <StatCard value="43,827" label="Training Pairs" sublabel="Human-labeled" />
                <StatCard value="78%" label="Best Accuracy" sublabel="Trained models" />
                <StatCard value="73%" label="Best OTS Judge" sublabel="Claude 3.5 Sonnet" />
              </div>

              {/* Pipeline Figure */}
              <FigureCard
                title="Figure 1: LitBench Pipeline"
                caption="Data collection pipeline from Reddit r/WritingPrompts, debiasing strategies, and evaluation methodology."
                expandedContent={
                  <div className="space-y-6">
                    <div className="flex flex-col md:flex-row items-center justify-center gap-4">
                      <div className="bg-orange-100 rounded-xl p-4 text-center min-w-32">
                        <div className="text-3xl mb-2">üìù</div>
                        <p className="font-semibold text-orange-800">r/WritingPrompts</p>
                        <p className="text-xs text-orange-600">Raw story pairs</p>
                      </div>
                      <div className="text-2xl text-gray-400 pipeline-arrow">‚Üí</div>
                      <div className="bg-blue-100 rounded-xl p-4 text-center min-w-32">
                        <div className="text-3xl mb-2">üîß</div>
                        <p className="font-semibold text-blue-800">Debiasing</p>
                        <p className="text-xs text-blue-600">Temporal, Length, Vote</p>
                      </div>
                      <div className="text-2xl text-gray-400 pipeline-arrow">‚Üí</div>
                      <div className="bg-purple-100 rounded-xl p-4 text-center min-w-32">
                        <div className="text-3xl mb-2">üéØ</div>
                        <p className="font-semibold text-purple-800">LitBench</p>
                        <p className="text-xs text-purple-600">2,480 test pairs</p>
                      </div>
                      <div className="text-2xl text-gray-400 pipeline-arrow">‚Üí</div>
                      <div className="bg-green-100 rounded-xl p-4 text-center min-w-32">
                        <div className="text-3xl mb-2">üìä</div>
                        <p className="font-semibold text-green-800">Evaluation</p>
                        <p className="text-xs text-green-600">Judge accuracy</p>
                      </div>
                    </div>
                    <div className="bg-gray-50 rounded-lg p-4">
                      <h4 className="font-semibold mb-2">Pipeline Details:</h4>
                      <ul className="text-sm text-gray-600 space-y-2">
                        <li>‚Ä¢ <strong>Collection:</strong> Stories from r/WritingPrompts after 2023</li>
                        <li>‚Ä¢ <strong>Pairing:</strong> Stories matched by writing prompt</li>
                        <li>‚Ä¢ <strong>Debiasing:</strong> 25%+ vote margin, newer preferred story, length-matched</li>
                        <li>‚Ä¢ <strong>Evaluation:</strong> Binary preference prediction task</li>
                      </ul>
                    </div>
                  </div>
                }
              >
                <div className="flex items-center justify-center gap-3 p-4 w-full">
                  <div className="bg-orange-100 rounded-lg p-3 text-center">
                    <div className="text-2xl">üìù</div>
                    <p className="text-xs mt-1">Reddit</p>
                  </div>
                  <span className="text-gray-400">‚Üí</span>
                  <div className="bg-blue-100 rounded-lg p-3 text-center">
                    <div className="text-2xl">üîß</div>
                    <p className="text-xs mt-1">Debias</p>
                  </div>
                  <span className="text-gray-400">‚Üí</span>
                  <div className="bg-purple-100 rounded-lg p-3 text-center">
                    <div className="text-2xl">üéØ</div>
                    <p className="text-xs mt-1">LitBench</p>
                  </div>
                  <span className="text-gray-400">‚Üí</span>
                  <div className="bg-green-100 rounded-lg p-3 text-center">
                    <div className="text-2xl">üìä</div>
                    <p className="text-xs mt-1">Eval</p>
                  </div>
                </div>
              </FigureCard>

              {/* Methodology */}
              <section className="poster-section p-6">
                <h2 className="text-2xl font-bold text-gray-800 mb-4 flex items-center gap-2">
                  <span className="text-3xl">üî¨</span> Methodology
                </h2>
                <div className="space-y-4">
                  <div>
                    <h3 className="font-semibold text-gray-800 mb-2">Off-the-Shelf (OTS) Judges</h3>
                    <p className="text-sm text-gray-600">
                      Zero-shot evaluation using frontier LLMs (GPT-4, Claude, DeepSeek) and
                      smaller open-source models (Llama, Qwen, Gemma) as preference judges.
                    </p>
                  </div>
                  <div className="border-t pt-4">
                    <h3 className="font-semibold text-gray-800 mb-2">Trained Reward Models</h3>
                    <div className="grid grid-cols-2 gap-3">
                      <div className="bg-blue-50 rounded-lg p-3">
                        <p className="font-medium text-blue-800 text-sm">Bradley-Terry</p>
                        <p className="text-xs text-blue-600">Pairwise preference learning</p>
                      </div>
                      <div className="bg-purple-50 rounded-lg p-3">
                        <p className="font-medium text-purple-800 text-sm">Generative</p>
                        <p className="text-xs text-purple-600">LM-based scoring</p>
                      </div>
                    </div>
                  </div>
                  <div className="border-t pt-4">
                    <h3 className="font-semibold text-gray-800 mb-2">Human Validation</h3>
                    <p className="text-sm text-gray-600">
                      Prospective study on <strong>newly generated LLM stories</strong> confirms
                      reward model alignment with human preferences.
                    </p>
                  </div>
                </div>
              </section>
            </div>

            {/* Right Column */}
            <div className="space-y-6">

              {/* Results Chart */}
              <FigureCard
                title="Figure 2: Model Accuracy Comparison"
                caption="Accuracy of different models on LitBench test set. Trained reward models outperform all off-the-shelf judges."
                expandedContent={
                  <div className="space-y-6">
                    <ResultsChart animated={false} />
                    <div className="grid grid-cols-2 gap-4 mt-4">
                      <div className="bg-emerald-50 rounded-lg p-4">
                        <h4 className="font-semibold text-emerald-800 mb-2">Key Finding</h4>
                        <p className="text-sm text-emerald-700">
                          Trained reward models achieve <strong>78% accuracy</strong>, outperforming
                          all off-the-shelf judges by 5+ percentage points.
                        </p>
                      </div>
                      <div className="bg-amber-50 rounded-lg p-4">
                        <h4 className="font-semibold text-amber-800 mb-2">Surprising Result</h4>
                        <p className="text-sm text-amber-700">
                          Chain-of-thought <strong>decreases accuracy</strong> to 72%, contrary to
                          code/math domains where CoT typically helps.
                        </p>
                      </div>
                    </div>
                  </div>
                }
              >
                <ResultsChart />
              </FigureCard>

              {/* Key Findings */}
              <section className="poster-section p-6">
                <h2 className="text-2xl font-bold text-gray-800 mb-4 flex items-center gap-2">
                  <span className="text-3xl">üí°</span> Key Findings
                </h2>
                <div className="space-y-4">
                  <div className="bg-emerald-50 border-l-4 border-emerald-500 p-4 rounded-r-lg">
                    <p className="font-semibold text-emerald-800">Trained &gt; Off-the-Shelf</p>
                    <p className="text-sm text-emerald-700">
                      Both Bradley-Terry and Generative reward models reach 78% accuracy,
                      surpassing Claude 3.5 Sonnet (73%) and GPT-4.1 (71%).
                    </p>
                  </div>
                  <div className="bg-red-50 border-l-4 border-red-500 p-4 rounded-r-lg">
                    <p className="font-semibold text-red-800">Small Models Struggle</p>
                    <p className="text-sm text-red-700">
                      Models under 10B parameters (Llama-8B, Qwen-7B, Gemma-7B) achieve only
                      56-60%‚Äîbarely above random chance.
                    </p>
                  </div>
                  <div className="bg-amber-50 border-l-4 border-amber-500 p-4 rounded-r-lg">
                    <p className="font-semibold text-amber-800">CoT Hurts Performance</p>
                    <p className="text-sm text-amber-700">
                      Chain-of-thought reasoning drops accuracy to 72%, suggesting creative
                      evaluation differs fundamentally from logical tasks.
                    </p>
                  </div>
                </div>
              </section>

              {/* Qualitative Insights */}
              <section className="poster-section p-6">
                <h2 className="text-2xl font-bold text-gray-800 mb-4 flex items-center gap-2">
                  <span className="text-3xl">üîç</span> What Makes Stories Win?
                </h2>
                <div className="grid grid-cols-2 gap-4">
                  <div>
                    <h3 className="font-semibold text-green-700 mb-2 flex items-center gap-1">
                      <span>‚úÖ</span> Preferred Stories
                    </h3>
                    <ul className="text-sm text-gray-600 space-y-1">
                      <li>‚Ä¢ Unexpected twists</li>
                      <li>‚Ä¢ Surprising humor</li>
                      <li>‚Ä¢ Clever punchlines</li>
                      <li>‚Ä¢ Creative wordplay</li>
                    </ul>
                  </div>
                  <div>
                    <h3 className="font-semibold text-red-700 mb-2 flex items-center gap-1">
                      <span>‚ùå</span> Rejected Stories
                    </h3>
                    <ul className="text-sm text-gray-600 space-y-1">
                      <li>‚Ä¢ Dry narratives</li>
                      <li>‚Ä¢ Lack of emotion</li>
                      <li>‚Ä¢ Confusing plots</li>
                      <li>‚Ä¢ Strange diction</li>
                    </ul>
                  </div>
                </div>
              </section>

              {/* Resources */}
              <section className="poster-section p-6 bg-gradient-to-br from-blue-50 to-purple-50">
                <h2 className="text-2xl font-bold text-gray-800 mb-4 flex items-center gap-2">
                  <span className="text-3xl">üîó</span> Resources
                </h2>
                <div className="space-y-3">
                  <a
                    href="https://arxiv.org/abs/2507.00769"
                    target="_blank"
                    rel="noopener noreferrer"
                    className="flex items-center gap-3 p-3 bg-white rounded-lg hover:shadow-md transition-shadow"
                  >
                    <span className="text-2xl">üìÑ</span>
                    <div>
                      <p className="font-semibold text-gray-800">Paper</p>
                      <p className="text-sm text-gray-500">arXiv:2507.00769</p>
                    </div>
                  </a>
                  <a
                    href="https://huggingface.co/collections/SAA-Lab/litbench-68267b5da3aafe58f9e43461"
                    target="_blank"
                    rel="noopener noreferrer"
                    className="flex items-center gap-3 p-3 bg-white rounded-lg hover:shadow-md transition-shadow"
                  >
                    <span className="text-2xl">ü§ó</span>
                    <div>
                      <p className="font-semibold text-gray-800">Dataset & Models</p>
                      <p className="text-sm text-gray-500">HuggingFace Collection</p>
                    </div>
                  </a>
                  <a
                    href="https://litbench.vercel.app/"
                    target="_blank"
                    rel="noopener noreferrer"
                    className="flex items-center gap-3 p-3 bg-white rounded-lg hover:shadow-md transition-shadow"
                  >
                    <span className="text-2xl">üèÜ</span>
                    <div>
                      <p className="font-semibold text-gray-800">Writing Evaluation Arena</p>
                      <p className="text-sm text-gray-500">litbench.vercel.app</p>
                    </div>
                  </a>
                </div>
              </section>
            </div>
          </div>
        </main>

        {/* Footer */}
        <footer className="bg-gray-100 px-8 py-6 border-t">
          <div className="max-w-6xl mx-auto flex flex-col md:flex-row items-center justify-between gap-4">
            <div className="flex items-center gap-4">
              <div className="text-3xl">üéì</div>
              <div>
                <p className="font-semibold text-gray-800">Stanford University</p>
                <p className="text-sm text-gray-500">SAA Lab</p>
              </div>
            </div>
            <div className="text-center md:text-right">
              <p className="text-sm text-gray-600">
                Questions? Contact us at <span className="font-medium">litbench@stanford.edu</span>
              </p>
              <p className="text-xs text-gray-400 mt-1">
                Interactive poster ‚Ä¢ Click figures to expand
              </p>
            </div>
          </div>
        </footer>
      </div>

      {/* Instructions overlay */}
      <div className="fixed bottom-4 right-4 no-print">
        <div className="bg-white/90 backdrop-blur rounded-full px-4 py-2 shadow-lg text-sm text-gray-600">
          üí° Click on figures to expand
        </div>
      </div>
    </div>
  );
}
