'use client';

import { FigureCard, StatCard, ResultsChart, DataTable, PipelineFigure, AblationTable, QRCode } from '@/components';

export default function Poster() {
  return (
    <div className="min-h-screen py-6 px-4">
      <div className="poster-container max-w-7xl mx-auto">

        {/* Header */}
        <header className="bg-[#1e3a5f] text-white p-6">
          <div className="max-w-6xl mx-auto">
            <div className="text-center">
              <p className="text-sm font-sans uppercase tracking-wider text-blue-200 mb-3">
                EACL 2025 · arXiv:2507.00769
              </p>
              <h1 className="text-3xl md:text-4xl font-bold font-sans leading-tight mb-4">
                LitBench: A Benchmark and Dataset for<br />
                Reliable Evaluation of Creative Writing
              </h1>
              <div className="flex flex-wrap justify-center gap-x-4 gap-y-1 text-sm mt-4">
                <span>Daniel Fein<sup>*</sup></span>
                <span>Sebastian Russo<sup>*</sup></span>
                <span>Violet Xiang</span>
                <span>Kabir Jolly</span>
                <span>Rafael Rafailov</span>
                <span>Nick Haber</span>
              </div>
              <p className="text-blue-200 text-sm mt-2 font-sans">
                Stanford University · <sup>*</sup>Equal contribution
              </p>
            </div>
          </div>
        </header>

        {/* Key Stats Bar */}
        <div className="grid grid-cols-4 border-b border-gray-300">
          <StatCard value="2,480" label="Test Pairs" sublabel="Debiased" />
          <StatCard value="43,827" label="Training Pairs" sublabel="Human-labeled" />
          <StatCard value="78%" label="Best Accuracy" sublabel="Trained RM" />
          <StatCard value="73%" label="Best Zero-Shot" sublabel="Claude-3.5" />
        </div>

        {/* Main Content */}
        <main className="p-4">
          <div className="grid grid-cols-1 lg:grid-cols-3 gap-4">

            {/* Column 1 */}
            <div className="space-y-4">

              {/* Abstract */}
              <section className="poster-section">
                <div className="poster-section-header">Abstract</div>
                <div className="p-4">
                  <p className="text-sm leading-relaxed">
                    Evaluating creative writing generated by large language models (LLMs) remains
                    challenging because open-ended narratives lack ground truths. We introduce
                    <strong> LitBench</strong>, the first standardized benchmark for creative writing
                    verification, comprising a held-out test set of <strong>2,480 debiased, human-labeled
                    story comparisons</strong> drawn from Reddit and a <strong>43,827-pair training corpus</strong>.
                    We benchmark zero-shot LLM judges and train reward models, finding that trained
                    models achieve <strong>78% accuracy</strong>, outperforming all off-the-shelf judges.
                  </p>
                </div>
              </section>

              {/* Motivation */}
              <section className="poster-section">
                <div className="poster-section-header">Motivation</div>
                <div className="p-4 space-y-3">
                  <div className="finding-box text-sm">
                    <strong>Problem:</strong> Open-ended creative writing lacks ground truth labels,
                    making automated evaluation difficult.
                  </div>
                  <div className="finding-box text-sm">
                    <strong>Current Approach:</strong> Off-the-shelf LLMs are used as zero-shot judges,
                    but their reliability for creative tasks is unclear.
                  </div>
                  <div className="finding-box finding-box-accent text-sm">
                    <strong>Our Goal:</strong> Create a vetted benchmark for reliable, automated
                    evaluation and optimization of creative writing systems.
                  </div>
                </div>
              </section>

              {/* Dataset */}
              <section className="poster-section">
                <div className="poster-section-header">Dataset Construction</div>
                <div className="p-4 space-y-3">
                  <p className="text-sm">
                    <strong>Source:</strong> Reddit r/WritingPrompts (post-2023, ensuring no LLM pretraining overlap)
                  </p>

                  <table className="data-table text-sm">
                    <thead>
                      <tr>
                        <th>Statistic</th>
                        <th>Value</th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr>
                        <td>Test comparisons</td>
                        <td className="font-semibold">2,480 pairs</td>
                      </tr>
                      <tr>
                        <td>Training pairs</td>
                        <td className="font-semibold">43,827 pairs</td>
                      </tr>
                      <tr>
                        <td>Unique stories (test)</td>
                        <td className="font-semibold">3,543</td>
                      </tr>
                      <tr>
                        <td>Avg. story length</td>
                        <td className="font-semibold">550 words</td>
                      </tr>
                    </tbody>
                  </table>

                  <div className="text-sm space-y-2 mt-3">
                    <p className="font-semibold font-sans text-xs uppercase text-gray-500">Debiasing Strategies:</p>
                    <ul className="space-y-1 text-sm">
                      <li><strong>Vote margin:</strong> ≥25% upvote difference for preference signal</li>
                      <li><strong>Temporal:</strong> Preferred story published later (removes exposure bias)</li>
                      <li><strong>Length:</strong> Pruning pairs with large length differences</li>
                    </ul>
                  </div>
                </div>
              </section>

              {/* Contributions */}
              <section className="poster-section">
                <div className="poster-section-header">Contributions</div>
                <div className="p-4">
                  <ol className="text-sm space-y-2 list-decimal list-inside">
                    <li>First standardized benchmark for creative writing verification with debiased human labels</li>
                    <li>Comprehensive evaluation of off-the-shelf LLM judges as zero-shot evaluators</li>
                    <li>Trained reward models using Bradley-Terry and generative approaches</li>
                    <li>Human validation study confirming model alignment with preferences</li>
                    <li>Public release of LitBench dataset and reward models on HuggingFace</li>
                  </ol>
                </div>
              </section>
            </div>

            {/* Column 2 */}
            <div className="space-y-4">

              {/* Pipeline Figure */}
              <FigureCard
                figureNumber={1}
                title="LitBench Pipeline"
                caption="Data collection pipeline from Reddit r/WritingPrompts through debiasing to final evaluation."
                expandedContent={
                  <div className="space-y-6">
                    <PipelineFigure expanded />
                    <div className="grid grid-cols-2 gap-4 text-sm">
                      <div className="border border-gray-200 p-3">
                        <p className="font-semibold font-sans text-xs uppercase text-gray-500 mb-2">Collection</p>
                        <p>Stories paired by writing prompt from r/WritingPrompts</p>
                      </div>
                      <div className="border border-gray-200 p-3">
                        <p className="font-semibold font-sans text-xs uppercase text-gray-500 mb-2">Filtering</p>
                        <p>Post-2023 only to avoid pretraining contamination</p>
                      </div>
                      <div className="border border-gray-200 p-3">
                        <p className="font-semibold font-sans text-xs uppercase text-gray-500 mb-2">Debiasing</p>
                        <p>Vote margin, temporal, and length controls</p>
                      </div>
                      <div className="border border-gray-200 p-3">
                        <p className="font-semibold font-sans text-xs uppercase text-gray-500 mb-2">Evaluation</p>
                        <p>Binary preference prediction task</p>
                      </div>
                    </div>
                  </div>
                }
              >
                <PipelineFigure />
              </FigureCard>

              {/* Methodology */}
              <section className="poster-section">
                <div className="poster-section-header">Methodology</div>
                <div className="p-4 space-y-4">
                  <div>
                    <p className="font-semibold font-sans text-sm mb-2">Off-the-Shelf (OTS) Judges</p>
                    <p className="text-sm">
                      Zero-shot evaluation using frontier LLMs (GPT-4, Claude, DeepSeek) and
                      smaller open-source models (Llama, Qwen, Gemma) as pairwise preference judges.
                    </p>
                  </div>

                  <div className="border-t pt-3">
                    <p className="font-semibold font-sans text-sm mb-2">Trained Reward Models</p>
                    <div className="grid grid-cols-2 gap-3 text-sm">
                      <div className="bg-gray-50 border border-gray-200 p-2">
                        <p className="font-semibold">Bradley-Terry (BT)</p>
                        <p className="text-xs text-gray-600">Pairwise preference learning on Llama-8B</p>
                      </div>
                      <div className="bg-gray-50 border border-gray-200 p-2">
                        <p className="font-semibold">Generative RM</p>
                        <p className="text-xs text-gray-600">LM-based scoring on Qwen</p>
                      </div>
                    </div>
                  </div>

                  <div className="border-t pt-3">
                    <p className="font-semibold font-sans text-sm mb-2">Human Validation</p>
                    <p className="text-sm">
                      Prospective study with 46 annotators on newly generated LLM stories,
                      confirming reward model alignment (57% vs 41% preference for best/worst).
                    </p>
                  </div>
                </div>
              </section>

              {/* Ablation Study */}
              <section className="poster-section">
                <div className="poster-section-header">Ablation Study</div>
                <div className="p-4">
                  <p className="text-sm mb-3">
                    Impact of debiasing on trained reward model performance:
                  </p>
                  <AblationTable />
                  <p className="text-xs text-gray-600 mt-3">
                    Debiasing contributes +13 percentage points to final accuracy.
                  </p>
                </div>
              </section>

              {/* Scaling */}
              <section className="poster-section">
                <div className="poster-section-header">Scaling Observations</div>
                <div className="p-4 space-y-2 text-sm">
                  <div className="finding-box">
                    <strong>BT models:</strong> Notable improvement up to 8B parameters
                  </div>
                  <div className="finding-box">
                    <strong>GenRM:</strong> Performance saturated earlier than BT
                  </div>
                  <div className="finding-box">
                    <strong>Zero-shot judges:</strong> Performance improved with model size
                  </div>
                </div>
              </section>
            </div>

            {/* Column 3 */}
            <div className="space-y-4">

              {/* Results Chart */}
              <FigureCard
                figureNumber={2}
                title="Model Accuracy Comparison"
                caption="Preference prediction accuracy on LitBench test set across trained reward models and off-the-shelf judges."
                expandedContent={
                  <div className="space-y-4">
                    <ResultsChart animated={false} />
                    <div className="mt-4">
                      <DataTable />
                    </div>
                  </div>
                }
              >
                <ResultsChart />
              </FigureCard>

              {/* Key Findings */}
              <section className="poster-section">
                <div className="poster-section-header">Key Findings</div>
                <div className="p-4 space-y-3">
                  <div className="finding-box text-sm">
                    <p className="font-semibold mb-1">Trained models outperform zero-shot</p>
                    <p>Both BT and GenRM achieve 78% accuracy, surpassing Claude-3.5 (73%) and GPT-4.1 (71%).</p>
                  </div>
                  <div className="finding-box text-sm">
                    <p className="font-semibold mb-1">Small models struggle</p>
                    <p>Models under 10B parameters (Llama-8B, Qwen-7B, Gemma-7B) achieve only 56-60%—barely above random.</p>
                  </div>
                  <div className="finding-box finding-box-accent text-sm">
                    <p className="font-semibold mb-1">Chain-of-thought hurts performance</p>
                    <p>CoT reasoning drops accuracy to 72%, suggesting creative evaluation differs from logical tasks.</p>
                  </div>
                </div>
              </section>

              {/* Qualitative Analysis */}
              <section className="poster-section">
                <div className="poster-section-header">Qualitative Analysis</div>
                <div className="p-4">
                  <div className="grid grid-cols-2 gap-4 text-sm">
                    <div>
                      <p className="font-semibold font-sans text-xs uppercase text-gray-500 mb-2">Preferred Stories</p>
                      <ul className="space-y-1">
                        <li>• Unexpected plot twists</li>
                        <li>• Surprising humor</li>
                        <li>• Clever punchlines</li>
                        <li>• Creative wordplay</li>
                      </ul>
                    </div>
                    <div>
                      <p className="font-semibold font-sans text-xs uppercase text-gray-500 mb-2">Rejected Stories</p>
                      <ul className="space-y-1">
                        <li>• Dry narratives</li>
                        <li>• Lack of emotional depth</li>
                        <li>• Confusing plots</li>
                        <li>• Strange diction</li>
                      </ul>
                    </div>
                  </div>
                  <p className="text-xs text-gray-600 mt-3 border-t pt-2">
                    <strong>Feature analysis:</strong> Plot discussion emerged as strongest predictor (+14.8% correctness).
                  </p>
                </div>
              </section>

              {/* Conclusions */}
              <section className="poster-section">
                <div className="poster-section-header">Conclusions</div>
                <div className="p-4 text-sm space-y-2">
                  <p>
                    LitBench provides a vetted resource for reliable, automated evaluation of
                    creative writing systems. Our findings suggest:
                  </p>
                  <ul className="list-disc list-inside space-y-1">
                    <li>Domain-specific training significantly improves evaluation quality</li>
                    <li>Chain-of-thought reasoning is not universally beneficial</li>
                    <li>Debiased human preferences are essential for training</li>
                  </ul>
                </div>
              </section>

              {/* Resources */}
              <section className="poster-section">
                <div className="poster-section-header">Resources</div>
                <div className="p-4">
                  {/* QR Codes */}
                  <div className="flex justify-center gap-6 mb-4 pb-4 border-b border-gray-200">
                    <QRCode
                      url="https://arxiv.org/abs/2507.00769"
                      label="Paper (arXiv)"
                    />
                    <QRCode
                      url="https://huggingface.co/collections/SAA-Lab/litbench-68267b5da3aafe58f9e43461"
                      label="Dataset (HF)"
                    />
                    <QRCode
                      url="https://litbench.vercel.app/"
                      label="Demo"
                    />
                  </div>

                  {/* Links */}
                  <div className="space-y-1.5 text-sm">
                    <a
                      href="https://arxiv.org/abs/2507.00769"
                      target="_blank"
                      rel="noopener noreferrer"
                      className="resource-link"
                    >
                      <span className="font-semibold font-sans">Paper:</span>
                      <span className="text-blue-600">arxiv.org/abs/2507.00769</span>
                    </a>
                    <a
                      href="https://huggingface.co/collections/SAA-Lab/litbench-68267b5da3aafe58f9e43461"
                      target="_blank"
                      rel="noopener noreferrer"
                      className="resource-link"
                    >
                      <span className="font-semibold font-sans">Dataset:</span>
                      <span className="text-blue-600">HuggingFace/SAA-Lab/litbench</span>
                    </a>
                    <a
                      href="https://litbench.vercel.app/"
                      target="_blank"
                      rel="noopener noreferrer"
                      className="resource-link"
                    >
                      <span className="font-semibold font-sans">Demo:</span>
                      <span className="text-blue-600">litbench.vercel.app</span>
                    </a>
                  </div>
                </div>
              </section>
            </div>
          </div>
        </main>

        {/* Footer */}
        <footer className="bg-gray-100 px-6 py-4 border-t border-gray-300">
          <div className="flex items-center justify-between text-sm text-gray-600">
            <div>
              <span className="font-semibold font-sans">Stanford University</span>
              <span className="mx-2">·</span>
              <span>SAA Lab</span>
            </div>
            <div className="text-xs">
              Contact: litbench@stanford.edu · Interactive poster: click figures to enlarge
            </div>
          </div>
        </footer>
      </div>
    </div>
  );
}
